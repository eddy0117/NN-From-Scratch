{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筆記\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def im2col(input_feat: np.ndarray, N, kh, kw, out_h, out_w, stride):\n",
    "    im2col_feat = []\n",
    "    for n in range(N):\n",
    "        for ih in range(out_h):\n",
    "            for iw in range(out_w):\n",
    "                im2col_feat.append(input_feat[n, :, stride * ih:stride * ih + kh, stride * iw:stride * iw + kw])\n",
    "                # each element -> (C, kh, kw)\n",
    "    # input_feat -> (N*out_h*out_w, C, kh, kw)\n",
    "\n",
    "    return np.array(im2col_feat).reshape(N * out_h * out_w, -1)\n",
    "\n",
    "def convolution(input_feat: np.ndarray, filter: np.ndarray, kh, kw, stride=1, padding=0, bias=None):\n",
    "    '''\n",
    "    input_feat: (N, C, H, W)\n",
    "    filter: (out_C, in_C, kH, kw)\n",
    "    bias: (out_C, 1)\n",
    "    '''\n",
    "    N, C, H, W = input_feat.shape\n",
    "    out_h = int((H - kh + 2 * padding) // stride) + 1\n",
    "    out_w = int((W - kw + 2 * padding) // stride) + 1\n",
    "    out_c = filter.shape[0]\n",
    "    \n",
    "    if padding:\n",
    "        input_feat = np.pad(input_feat, ((0, 0), (0, 0), (padding, padding), (padding, padding)), 'constant', constant_values=0)\n",
    "\n",
    "    im2col_feat = im2col(input_feat, N, kh, kw, out_h, out_w, stride)\n",
    "    # im2col -> (N*out_h*out_w, C*kh*kw)\n",
    "\n",
    "    filter = filter.reshape(out_c, -1)\n",
    "    # filter -> (out_c, C*kh*kw)\n",
    "\n",
    "    # w @ x.T\n",
    "    # w -> (out_c, C*kh*kw)\n",
    "    # x.T -> (C*kh*kw, N*out_h*out_w)\n",
    "    if isinstance(bias, np.ndarray):\n",
    "        out_feat = filter @ im2col_feat.T + bias\n",
    "    else:\n",
    "        out_feat = filter @ im2col_feat.T\n",
    "    # out_feat -> (out_c, N*out_h*out_w)\n",
    "    \n",
    "    # 直接將 (out_c, N*out_h*out_w) reshape 成 (N, out_c, out_h, out_w) 會產生順序錯亂\n",
    "    # 所以先將 (out_c, N*out_h*out_w) 拆成 (out_c, N, out_h, out_w) 後再 permute\n",
    "    # out_feat -> (N, out_c, out_h, out_w)\n",
    "    return out_feat.reshape(out_c, N, out_h, out_w).transpose(1, 0, 2, 3)\n",
    "    # return out_feat.T.reshape(N, out_h, out_w, out_c).transpose(0, 3, 1, 2)\n",
    "   \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# input feat (c, h, w) -> (3, 3, 3)\n",
    "# filter (out_c, in_c, kh, kw) -> (3, 3, 2, 2)\n",
    "# bias (out_c, 1)\n",
    "bs = 2\n",
    "feat_h = 3\n",
    "feat_w = 3\n",
    "kh = 2\n",
    "kw = 2\n",
    "in_c = 3\n",
    "out_c = 3\n",
    "padding = 0\n",
    "stride = 1\n",
    "\n",
    "input_feat = np.random.randint(0, 20, size=(bs, in_c, feat_h, feat_w)).astype(np.float32)\n",
    "filter = np.random.randint(0, 5, size=(out_c, in_c, kh, kw)).astype(np.float32)\n",
    "# bias = np.random.randint(0, 5, size=(2, 1))\n",
    "bias = np.zeros((out_c, 1), dtype=np.float32)\n",
    "\n",
    "out = convolution(input_feat, filter, kh=kh, kw=kw, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "# 與 pytorch 的實現方法對照結果\n",
    "out_t = F.conv2d(torch.tensor(input_feat), torch.tensor(filter), stride=stride, padding=padding, bias=torch.tensor(bias).squeeze(1))\n",
    "\n",
    "\n",
    "print(f'input feat:\\n{input_feat}')\n",
    "print('======================')\n",
    "print(f'filter\\n:{filter}')\n",
    "print('======================')\n",
    "print(f'my out:\\n{out}')\n",
    "print(f'torch out:\\n{out_t.numpy()}')\n",
    "np.allclose(out, out_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from my_mlp import MLP, CrossEntropyLoss\n",
    "from my_nn_lib import ReLU, Softmax, LeckyReLU, Linear, BaseModule, Conv2d, Flatten\n",
    "\n",
    "# import mnist\n",
    "\n",
    "\n",
    "\n",
    "class MyModel(MLP):\n",
    "    def __init__(self, layer_list):\n",
    "        self.layers = layer_list\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def backward(self, X, label):\n",
    "\n",
    "        idx_maxlayer = len(self.layers)-1\n",
    "        dLdZ = label\n",
    "\n",
    "        for idx in range(idx_maxlayer, -1, -1):\n",
    "            # 倒敘遍歷\n",
    "\n",
    "            dLdZ = self.layers[idx].backward(delta=dLdZ)\n",
    "            \n",
    "    \n",
    "    def update_params(self, opt_params):\n",
    "        for layer in self.layers:\n",
    "            layer.update_params(opt_params)\n",
    "        \n",
    "    def get_pred(self, X, with_onehot=False):\n",
    "        pred = self.forward(X)\n",
    "        if with_onehot:\n",
    "            return pred\n",
    "        return np.argmax(pred, axis=1)\n",
    "\n",
    "    def train(self, X_train, Y_train, X_val, Y_val, loss_func, hyper_params: dict, show_plot=False):\n",
    "        # X_train -> (n_samples, n_features)\n",
    "        # Y_train -> (n_samples, n_classes) one-hot \n",
    "        \n",
    "        # params = self.weight_init(self.params_set_list)\n",
    "\n",
    "        n_samples = X_train.shape[0]\n",
    "\n",
    "        # 將 train data 打包成 batch\n",
    "        X_batch_all, Y_batch_all = self.pack_to_batch(X_train, Y_train, hyper_params['batch_size'], n_samples)\n",
    "        \n",
    "        train_loss_arr = []\n",
    "        val_loss_arr = []\n",
    "        \n",
    "        val_acc_arr = []\n",
    "\n",
    "        for i in range(hyper_params['epoch']):\n",
    "            loss = 0\n",
    "            print(\"Epoch: \", i)\n",
    "            with tqdm(total=len(X_batch_all)) as pbar:\n",
    "                for idx, (X_batch, Y_batch) in enumerate(zip(X_batch_all, Y_batch_all)):\n",
    "                    # 單個 batch 訓練過程\n",
    "                    # 1. 前向傳播\n",
    "                    # 2. 反向傳播\n",
    "                    # 3. 更新權重   \n",
    "                    self.forward(X_batch)\n",
    "                    self.backward(X_batch, Y_batch)\n",
    "                    self.update_params({'lr': hyper_params['lr'], 'alpha': hyper_params['alpha']})\n",
    "                    loss += loss_func.cal_loss(self.get_pred(X_batch, with_onehot=True), Y_batch)\n",
    "                    pbar.update(1)\n",
    "            print(\"Epoch: \", i)\n",
    "            print('Loss:', round(loss, 2) / hyper_params['batch_size'])\n",
    "\n",
    "            predictions = self.get_pred(X_val)\n",
    "            print('Val Acc:', round(self.calculate_acc(predictions, Y_val), 2))\n",
    "            \n",
    "            train_loss_arr.append(loss / n_samples)\n",
    "\n",
    "            # 取 output layer 經過 activation function 的結果為 prediction\n",
    "            val_loss_arr.append(loss_func.cal_loss(self.get_pred(X_val, with_onehot=True), Y_val) / len(X_val))\n",
    "            val_acc_arr.append(self.calculate_acc(predictions, Y_val))\n",
    "\n",
    "        if show_plot:\n",
    "            self.plot_loss_acc(train_loss_arr, val_loss_arr, val_acc_arr)\n",
    "\n",
    "        return train_loss_arr, val_loss_arr, val_acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 8, 8)\n",
      "(2, 3, 6, 6)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 36 is different from 108)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m MyModel([Conv2d(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), \n\u001b[1;32m      8\u001b[0m                 LeckyReLU(),\n\u001b[1;32m      9\u001b[0m                 Conv2d(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     10\u001b[0m                 Flatten(),\n\u001b[1;32m     11\u001b[0m                 Linear(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     12\u001b[0m                 Softmax()])\n\u001b[1;32m     14\u001b[0m hyper_params \u001b[38;5;241m=\u001b[39m {    \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m     19\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m, in \u001b[0;36mMyModel.train\u001b[0;34m(self, X_train, Y_train, X_val, Y_val, loss_func, hyper_params, show_plot)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, Y_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_batch_all, Y_batch_all):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# 單個 batch 訓練過程\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# 1. 前向傳播\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# 2. 反向傳播\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# 3. 更新權重   \u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_batch)\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_params({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: hyper_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: hyper_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m     62\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_func\u001b[38;5;241m.\u001b[39mcal_loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pred(X_batch, with_onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), Y_batch)\n",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m, in \u001b[0;36mMyModel.backward\u001b[0;34m(self, X, label)\u001b[0m\n\u001b[1;32m     18\u001b[0m dLdZ \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(idx_maxlayer, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# 倒敘遍歷\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     dLdZ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdLdZ\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/NumpyImplenmentNN/my_nn_lib/layers/conv.py:52\u001b[0m, in \u001b[0;36mConv2d.backward\u001b[0;34m(self, delta)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, delta):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#  back_prop_params: {'delta_next': delta_next, \u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m#                     'w_next': w_next, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m#  如果 next layer 是 flatten\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m#  dLdZ -> (N, out_c*out_h*out_w)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     dLdZ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_dLdZ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     dW, db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcal_dLdW(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_feat, delta)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_delta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dW\n",
      "File \u001b[0;32m~/Programs/NumpyImplenmentNN/my_nn_lib/layers/conv.py:79\u001b[0m, in \u001b[0;36mConv2d.cal_dLdZ\u001b[0;34m(self, delta, filter)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# 每個 out_c 是將 in_c 個 filters conv 後的結果相加\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# 所以 backward 時梯度要複製成 in_c 個\u001b[39;00m\n\u001b[1;32m     77\u001b[0m dilated_delta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(dilated_delta, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 79\u001b[0m dLdZ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdilated_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dLdZ\n",
      "File \u001b[0;32m~/Programs/NumpyImplenmentNN/my_nn_lib/layers/conv.py:168\u001b[0m, in \u001b[0;36mConv2d.convolution\u001b[0;34m(self, input_feat, filter, bias, stride, is_dLdW)\u001b[0m\n\u001b[1;32m    166\u001b[0m     out_feat \u001b[38;5;241m=\u001b[39m (im2col_feat \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m+\u001b[39m bias)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     out_feat \u001b[38;5;241m=\u001b[39m (\u001b[43mim2col_feat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# out_feat -> (out_c, N*out_h*out_w)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# 將 w 重新 reshape 成 (out_c, in_c, kh, kw)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# self.w = self.w.reshape(out_c, C, kh, kw)\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dLdW:\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 36 is different from 108)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# making some dummy data about 3 images with 3 channels and labels\n",
    "images = np.random.randint(0, 255, size=(4, 3, 10, 10)).astype(np.float32) / 255\n",
    "labels = np.array([[0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "model = MyModel([Conv2d(3, 4, (3, 3), 1, 0), \n",
    "                LeckyReLU(),\n",
    "                Conv2d(4, 3, (3, 3), 1, 0),\n",
    "                Flatten(),\n",
    "                Linear(3*6*6, 3),\n",
    "                Softmax()])\n",
    "\n",
    "hyper_params = {    \n",
    "    'lr': 0.01,\n",
    "    'epoch': 50,\n",
    "    'batch_size': 2,\n",
    "    'alpha': 0.9\n",
    "}\n",
    "model.train(images, labels, images, labels, CrossEntropyLoss, hyper_params, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 固定隨機種子，確保同參數下每次結果都相同\n",
    "np.random.seed(1)\n",
    "\n",
    "def wine():\n",
    "    with open('data/winequality-red.csv') as f:\n",
    "        # 跳過 first row (標籤名稱)\n",
    "        data = f.readlines()[1:]\n",
    "\n",
    "    data = [line.strip().split(',') for line in data]\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = []\n",
    "\n",
    "    # 最後一個 column 為 label\n",
    "    classes = np.unique(data[:, -1])\n",
    "\n",
    "    # 將 label 做 one-hot encoding\n",
    "    for d in data:\n",
    "        for cls in classes:\n",
    "            if d[-1] == cls:\n",
    "                one_hot = np.zeros(len(classes))\n",
    "                one_hot[classes.tolist().index(cls)] = 1\n",
    "                labels.append(one_hot)\n",
    "    return data, labels\n",
    "\n",
    "def iris():\n",
    "    with open('data/Iris.csv') as f:\n",
    "    # 跳過 first row (標籤名稱)\n",
    "        data = f.readlines()[1:]\n",
    "\n",
    "    data = [line.strip().split(',')[1:] for line in data]\n",
    "    data = np.array(data)\n",
    "    labels = []\n",
    "\n",
    "    classes = np.unique(data[:, 4])\n",
    "\n",
    "    # 將 label 做 one-hot encoding\n",
    "    for d in data:\n",
    "        for cls in classes:\n",
    "            if d[4] == cls:\n",
    "                one_hot = np.zeros(len(classes))\n",
    "                one_hot[classes.tolist().index(cls)] = 1\n",
    "                labels.append(one_hot)\n",
    "    return data, labels\n",
    "\n",
    "# data, labels = iris()\n",
    "data, labels = wine()\n",
    "# 將 input features 與 labels 從原始資料中分離\n",
    "inputs = data[:, :-1].astype(np.float32)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 對 input features 做標準化\n",
    "inputs = (inputs - np.mean(inputs, axis=0)) / np.std(inputs, axis=0)\n",
    "\n",
    "# 打亂數據\n",
    "idx = np.random.permutation(len(inputs))\n",
    "\n",
    "X_data = inputs[idx]\n",
    "Y_data = labels[idx]\n",
    "\n",
    "# 設定 train set 和 val set 的比例 (80% train, 20% val)\n",
    "train_size = int(len(X_data) * 0.80)\n",
    "\n",
    "\n",
    "X_train, Y_train = X_data[:train_size], Y_data[:train_size]\n",
    "X_val, Y_val = X_data[train_size:], Y_data[train_size:]\n",
    "\n",
    "hyper_params = {\n",
    "    'lr': 0.01,\n",
    "    'epoch': 50,\n",
    "    'batch_size': 16,\n",
    "    'alpha': 0.9\n",
    "}\n",
    "\n",
    "\n",
    "model = MyModel([Linear(11, 6), \n",
    "                 LeckyReLU(),\n",
    "                 Linear(6, 6),\n",
    "                 Softmax()])\n",
    "\n",
    "# model = MyModel([Linear(4, 3), Softmax()])\n",
    "\n",
    "params = model.train(X_train, Y_train, X_val, Y_val, CrossEntropyLoss, hyper_params, show_plot=True)\n",
    "# mlp.kfold(X_data, Y_data, FOLD, SquareLoss, hyper_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      " [[[[ 6.  0.  6.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 1.  0. 19.]]\n",
      "\n",
      "  [[16.  0. 12.]\n",
      "   [ 0.  0.  0.]\n",
      "   [18.  0. 18.]]\n",
      "\n",
      "  [[16.  0. 11.]\n",
      "   [ 0.  0.  0.]\n",
      "   [18.  0. 17.]]]]\n"
     ]
    }
   ],
   "source": [
    "images = np.random.randint(0, 255, size=(4, 3, 5, 5)).astype(np.float32)\n",
    "labels = np.array([[0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "model = MyModel([Conv2d(3, 1, (3, 3), 2, 0), \n",
    "                LeckyReLU(),\n",
    "                Flatten(),\n",
    "                Linear(2*2*1, 3),\n",
    "                Softmax()])\n",
    "\n",
    "hyper_params = {    \n",
    "    'lr': 0.01,\n",
    "    'epoch': 2,\n",
    "    'batch_size': 2,\n",
    "    'alpha': 0.9\n",
    "}\n",
    "model.train(images, labels, images, labels, CrossEntropyLoss, hyper_params, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[[[12. 19.  9. 17.  2.  7. 18.]\n",
      "   [ 2.  8.  7. 15. 17.  2. 11.]\n",
      "   [ 9.  3. 13.  5. 12.  4.  5.]\n",
      "   [17. 10.  9.  5. 17.  8. 13.]\n",
      "   [ 6. 19.  3. 13. 10.  6.  4.]\n",
      "   [ 4.  9. 17. 11.  6.  2.  0.]\n",
      "   [ 8. 18. 17. 18.  4. 11.  0.]]]\n",
      "\n",
      "\n",
      " [[[18.  4.  5. 12.  8.  7. 16.]\n",
      "   [15. 11. 11. 19. 18. 13.  8.]\n",
      "   [ 5. 14. 10.  4.  3. 13.  1.]\n",
      "   [ 1. 15. 15. 19. 13.  1.  2.]\n",
      "   [18. 15. 19.  5. 17.  5. 13.]\n",
      "   [16.  2.  1.  5.  6.  0. 19.]\n",
      "   [15.  0. 19.  5. 18. 15. 13.]]]]\n",
      "b:\n",
      " [[[[12. 19.  9. 17.  2.  7. 18.]\n",
      "   [ 2.  8.  7. 15. 17.  2. 11.]\n",
      "   [ 9.  3. 13.  5. 12.  4.  5.]\n",
      "   [17. 10.  9.  5. 17.  8. 13.]\n",
      "   [ 6. 19.  3. 13. 10.  6.  4.]\n",
      "   [ 4.  9. 17. 11.  6.  2.  0.]\n",
      "   [ 8. 18. 17. 18.  4. 11.  0.]]\n",
      "\n",
      "  [[12. 19.  9. 17.  2.  7. 18.]\n",
      "   [ 2.  8.  7. 15. 17.  2. 11.]\n",
      "   [ 9.  3. 13.  5. 12.  4.  5.]\n",
      "   [17. 10.  9.  5. 17.  8. 13.]\n",
      "   [ 6. 19.  3. 13. 10.  6.  4.]\n",
      "   [ 4.  9. 17. 11.  6.  2.  0.]\n",
      "   [ 8. 18. 17. 18.  4. 11.  0.]]\n",
      "\n",
      "  [[12. 19.  9. 17.  2.  7. 18.]\n",
      "   [ 2.  8.  7. 15. 17.  2. 11.]\n",
      "   [ 9.  3. 13.  5. 12.  4.  5.]\n",
      "   [17. 10.  9.  5. 17.  8. 13.]\n",
      "   [ 6. 19.  3. 13. 10.  6.  4.]\n",
      "   [ 4.  9. 17. 11.  6.  2.  0.]\n",
      "   [ 8. 18. 17. 18.  4. 11.  0.]]]\n",
      "\n",
      "\n",
      " [[[18.  4.  5. 12.  8.  7. 16.]\n",
      "   [15. 11. 11. 19. 18. 13.  8.]\n",
      "   [ 5. 14. 10.  4.  3. 13.  1.]\n",
      "   [ 1. 15. 15. 19. 13.  1.  2.]\n",
      "   [18. 15. 19.  5. 17.  5. 13.]\n",
      "   [16.  2.  1.  5.  6.  0. 19.]\n",
      "   [15.  0. 19.  5. 18. 15. 13.]]\n",
      "\n",
      "  [[18.  4.  5. 12.  8.  7. 16.]\n",
      "   [15. 11. 11. 19. 18. 13.  8.]\n",
      "   [ 5. 14. 10.  4.  3. 13.  1.]\n",
      "   [ 1. 15. 15. 19. 13.  1.  2.]\n",
      "   [18. 15. 19.  5. 17.  5. 13.]\n",
      "   [16.  2.  1.  5.  6.  0. 19.]\n",
      "   [15.  0. 19.  5. 18. 15. 13.]]\n",
      "\n",
      "  [[18.  4.  5. 12.  8.  7. 16.]\n",
      "   [15. 11. 11. 19. 18. 13.  8.]\n",
      "   [ 5. 14. 10.  4.  3. 13.  1.]\n",
      "   [ 1. 15. 15. 19. 13.  1.  2.]\n",
      "   [18. 15. 19.  5. 17.  5. 13.]\n",
      "   [16.  2.  1.  5.  6.  0. 19.]\n",
      "   [15.  0. 19.  5. 18. 15. 13.]]]]\n",
      "(2, 1, 7, 7) (2, 3, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randint(0, 20, size=(2, 1, 7, 7)).astype(np.float32)\n",
    "b = np.tile(a, (1, 3, 1, 1))\n",
    "print('a:\\n', a)\n",
    "print('b:\\n', b)\n",
    "print(a.shape, b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tensor(np.ndarray):\n",
    "    def __new__(cls, input_array, requires_grad=False):\n",
    "        # 建立 ndarray 的子類\n",
    "        obj = np.asarray(input_array).view(cls)\n",
    "        obj.requires_grad = requires_grad\n",
    "        obj.grad = None  # 儲存梯度\n",
    "        obj._grad_fn = None  # 計算梯度的函數\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        # 當新 Tensor 被創建時，繼承屬性\n",
    "        if obj is None: return\n",
    "        self.requires_grad = getattr(obj, 'requires_grad', False)\n",
    "        self.grad = getattr(obj, 'grad', None)\n",
    "        self._grad_fn = getattr(obj, '_grad_fn', None)\n",
    "\n",
    "    def backward(self, grad_output=None):\n",
    "        if not self.requires_grad:\n",
    "            raise RuntimeError(\"This tensor does not require gradients.\")\n",
    "        \n",
    "        if grad_output is None:\n",
    "            grad_output = np.ones_like(self)\n",
    "        \n",
    "        if self.grad is None:\n",
    "            self.grad = grad_output\n",
    "        else:\n",
    "            self.grad += grad_output\n",
    "\n",
    "        if self._grad_fn:\n",
    "            self._grad_fn(grad_output)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tensor({super().__repr__()}, requires_grad={self.requires_grad})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(Tensor([[1, 2],\n",
       "        [3, 4]]), requires_grad=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[1, 2], [3, 4]])\n",
    "a = Tensor(b)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[[17.  2.]\n",
      "  [ 6. 16.]]\n",
      "\n",
      " [[10. 17.]\n",
      "  [10.  0.]]\n",
      "\n",
      " [[11. 10.]\n",
      "  [16.  0.]]]\n",
      "b:\n",
      " [[[ 5. 18.]\n",
      "  [ 0. 18.]]\n",
      "\n",
      " [[ 4.  5.]\n",
      "  [19. 17.]]\n",
      "\n",
      " [[15. 15.]\n",
      "  [19.  1.]]]\n",
      "ab\n",
      " [[[ 85. 342.]\n",
      "  [ 30. 396.]]\n",
      "\n",
      " [[363. 339.]\n",
      "  [ 40.  50.]]\n",
      "\n",
      " [[355. 175.]\n",
      "  [240. 240.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randint(0, 20, size=(3, 2, 2)).astype(np.float32)\n",
    "b = np.random.randint(0, 20, size=(3, 2, 2)).astype(np.float32)\n",
    "print('a:\\n', a)\n",
    "print('b:\\n', b)\n",
    "print('ab\\n', a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 18/33 [02:22<01:58,  7.91s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = 'data/MNIST'\n",
    "\n",
    "class_paths = os.listdir(path)\n",
    "\n",
    "x_all = []\n",
    "y_all = []\n",
    "\n",
    "for cls_path in class_paths:\n",
    "    img_paths = os.listdir(os.path.join(path, cls_path))\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(os.path.join(path, cls_path, img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "        x_all.append(img)\n",
    "        y_all.append(int(cls_path))\n",
    "x_all = np.array(x_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "x_all = x_all.reshape(-1, 1, 28, 28) / 255\n",
    "\n",
    "# one-hot encoding\n",
    "y_one_hot = np.zeros((len(y_all), 10))\n",
    "y_one_hot[np.arange(len(y_all)), y_all] = 1\n",
    "\n",
    "# shuffle data\n",
    "idx = np.arange(len(x_all))\n",
    "np.random.shuffle(idx)\n",
    "x_all = x_all[idx]\n",
    "y_one_hot = y_one_hot[idx]\n",
    "\n",
    "\n",
    "\n",
    "# split train and val\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(x_all) * split_ratio)\n",
    "x_train = x_all[:split_idx]\n",
    "y_train = y_one_hot[:split_idx]\n",
    "x_val = x_all[split_idx:]\n",
    "y_val = y_one_hot[split_idx:]\n",
    "\n",
    "# making some dummy data about 3 images with 3 channels and labels\n",
    "# images = np.random.randint(0, 255, size=(4, 3, 28, 28)).astype(np.float32) / 255\n",
    "# labels = np.array([[0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "model = MyModel([Conv2d(1, 4, (11, 11), 1, 0), \n",
    "                LeckyReLU(),\n",
    "                Conv2d(4, 2, (11, 11), 1, 0),\n",
    "                LeckyReLU(),\n",
    "                Flatten(),\n",
    "                Linear(2*8*8, 10),\n",
    "                Softmax()])\n",
    "\n",
    "hyper_params = {    \n",
    "    'lr': 0.01,\n",
    "    'epoch': 50,\n",
    "    'batch_size': 1024,\n",
    "    'alpha': 0.9\n",
    "}\n",
    "model.train(x_train, y_train, x_val, y_val, CrossEntropyLoss, hyper_params, show_plot=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idx = 9\n",
    "plt.imshow(x_val[idx].reshape(28, 28), cmap='gray')\n",
    "model.get_pred(np.expand_dims(x_val[idx], axis=0), with_onehot=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7c79fae95a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.layers[0].w.shape\n",
    "\n",
    "plt.imshow(model.layers[0].w[0, 0], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparsedrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
